{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagehash import phash, dhash, average_hash\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import FunctionType\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from numpy import array\n",
    "\n",
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Class wrapper to instantiate a Dataset object composing of a subset of test images\n",
    "    and a smaller fraction of images that are used as queries to test search and retrieval.\n",
    "    Object contains hashed image fingerprints as well, however, hashing method is set by user.\n",
    "    \"\"\"\n",
    "    def __init__(self, path_to_queries: str, path_to_test: str) -> None:\n",
    "        #print(path_to_queries, path_to_test)\n",
    "        self.query_docs = self.load_image_set(path_to_queries)\n",
    "        self.test_docs = self.load_image_set(path_to_test)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_image_set(path: str) -> dict: \n",
    "        return {doc: os.path.join(path, doc) for doc in os.listdir(path) if doc.endswith('.jpg')}\n",
    "\n",
    "    \n",
    "class HashedDataset(Dataset):\n",
    "    def __init__(self, hashing_function: FunctionType, *args, **kwargs) -> None:\n",
    "        super(HashedDataset, self).__init__(*args, **kwargs)\n",
    "        self.hasher = hashing_function\n",
    "        # self.test_hashes = {doc: str(self.hasher(Image.open(self.test_docs[doc]))) for doc in self.test_docs}\n",
    "        # self.query_hashes = {doc: str(self.hasher(Image.open(self.query_docs[doc]))) for doc in self.query_docs}\n",
    "        self.fingerprint()\n",
    "        self.doc2hash = deepcopy(self.test_hashes)\n",
    "        self.doc2hash.update(self.query_hashes)\n",
    "        self.hash2doc = {self.doc2hash[doc]: doc for doc in self.doc2hash}\n",
    "\n",
    "    \n",
    "    def fingerprint(self) -> None:\n",
    "        self.test_hashes = {doc: str(self.hasher(Image.open(self.test_docs[doc]))) for doc in self.test_docs}\n",
    "        self.query_hashes = {doc: str(self.hasher(Image.open(self.query_docs[doc]))) for doc in self.query_docs}\n",
    "        \n",
    "        \n",
    "    def get_hashes(self) -> dict:\n",
    "        return self.doc2hash\n",
    "\n",
    "\n",
    "    def get_query_hashes(self) -> dict:\n",
    "        return self.query_hashes\n",
    "\n",
    "\n",
    "    def get_test_hashes(self) -> dict:\n",
    "        return self.test_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hull = HashedDataset(\n",
    "    dhash,\n",
    "    '/Users/zubin.john/forge/image-dedup/Transformed_dataset/Query/',\n",
    "    '/Users/zubin.john/forge/image-dedup/Transformed_dataset/Retrieval/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "\n",
    "class ResultSet:\n",
    "    \"\"\"In order to retrieve duplicate images an index needs to be built against which\n",
    "    search operations are run. The ResultSe Class serves as a search and retrieval\n",
    "    interface, essential for driving interfacing for downstream tasks.\n",
    "\n",
    "    Takes input dictionary of image hashes for which DB has to be created.\"\"\"\n",
    "    def __init__(self, index_save_path: str, candidates:dict, queries: dict) -> None:\n",
    "        self.db_path = index_save_path\n",
    "        self.db = self.create_db_index(index_save_path)\n",
    "        self.populate_db(candidates)\n",
    "        self.fetch_nearest_neighbors(queries)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_db_index(path) -> shelve.DbfilenameShelf:\n",
    "        return shelve.open(path, writeback = True)\n",
    "\n",
    "\n",
    "    def refresh_db_buffer(self) -> shelve.DbfilenameShelf:\n",
    "        return shelve.open(self.db_path)\n",
    "\n",
    "\n",
    "    def populate_db(self, candidates: dict):\n",
    "        for each in candidates:\n",
    "            self.db[candidates[each]] = self.db.get(candidates[each], []) + [each]\n",
    "        # Close the shelf database\n",
    "        self.db.close()\n",
    "\n",
    "\n",
    "    def fetch_nearest_neighbors(self, queries) -> None:\n",
    "        self.db = self.refresh_db_buffer()\n",
    "        self.query_results = {query: self.db[queries[query]] for query in queries}\n",
    "        self.db.close()\n",
    "\n",
    "        \n",
    "    def destroy_db_index(self) -> None:\n",
    "        if self.query_results:\n",
    "            os.remove(self.db_path)\n",
    "            \n",
    "    def retrieve_results(self):\n",
    "        return self.query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashes = hull.get_hashes()\n",
    "queries = hull.get_query_hashes()\n",
    "\n",
    "res = ResultSet('../Transformed_dataset/imageset', hashes, queries).retrieve_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unit test\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "x = np.array(Image.open('/Users/zubin.john/forge/image-dedup/Transformed_dataset/Retrieval/ukbench04754_vflip.jpg'))\n",
    "y = Image.open('/Users/zubin.john/forge/image-dedup/Transformed_dataset/Retrieval/ukbench04754_vflip.jpg')           \n",
    "\n",
    "assert dhash(Image.fromarray(x)) == dhash(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
